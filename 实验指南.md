# AE-LSTM 盐度预测实验指南

本指南将详细介绍如何使用AE-LSTM盐度预测框架进行实验，包括模型配置、训练流程和结果分析。

## 目录
- [快速开始](#快速开始)
- [实验环境准备](#实验环境准备)
- [模型架构选择](#模型架构选择)
- [配置文件详解](#配置文件详解)
- [实验流程](#实验流程)
- [高级实验](#高级实验)
- [结果分析](#结果分析)
- [常见问题](#常见问题)

## 快速开始

### 1. 环境安装

```bash
# 克隆项目
git clone <项目地址>
cd AE_LSTM

# 安装基础依赖
pip install -r requirements.txt

# 根据需要安装额外依赖
# Mamba模型需要
pip install mamba-ssm

# 性能优化
pip install flash-attn
```

### 2. 第一次运行

```bash
# 使用默认LSTM配置运行
python main_pipeline.py

# 使用小数据集进行快速测试
python main_pipeline.py data.dataset.use_mini_dataset=true
```

## 实验环境准备

### 数据准备

项目需要以下数据文件（位于`data/`目录）：
- `salinity.npy`: 盐度数据（主要预测目标）
- `flow.npy`: 流量数据
- `wind_u.npy`, `wind_v.npy`: 风速数据
- `runoff.npy`: 径流数据
- 网格和坐标文件

### 检查数据完整性

```bash
# 查看数据文件
ls -la data/

# 检查数据形状（可选）
python -c "import numpy as np; print('盐度数据形状:', np.load('data/salinity.npy').shape)"
```

## 模型架构选择

### 1. LSTM模型（推荐入门）

```bash
# 基础LSTM实验
python main_pipeline.py model.name=lstm

# 双向LSTM
python main_pipeline.py model.name=lstm model_configs.bidirectional=true

# 多层LSTM
python main_pipeline.py model.name=lstm model_configs.num_layers=3
```

### 2. Mamba模型（推荐长序列）

```bash
# 基础Mamba实验
python main_pipeline.py model.name=mamba

# 调整状态空间维度
python main_pipeline.py model.name=mamba model_configs.d_state=32

# 调整模型维度
python main_pipeline.py model.name=mamba model_configs.d_model=256
```


### 3. Transformer模型（推荐复杂模式）

```bash
# 基础Transformer实验
python main_pipeline.py model.name=transformer

# 调整注意力头数
python main_pipeline.py model.name=transformer model_configs.n_heads=12

# 调整层数
python main_pipeline.py model.name=transformer model_configs.n_layers=8
```

## 配置文件详解

### 主配置文件 (`conf/config.yaml`)

```yaml
# 模型选择
model:
  name: lstm  # 可选: lstm, mamba, transformer
  
# 实验设置
experiment:
  name: "my_experiment"
  seed: 42
  device: "cuda"  # 或 "cpu"

# 数据设置
data:
  dataset:
    use_mini_dataset: false  # 是否使用小数据集
    sequence_length: 10      # 序列长度
```

### 模型特定配置

#### LSTM配置 (`conf/model_configs/lstm.yaml`)
```yaml
hidden_size: 128        # 隐藏层维度
num_layers: 2          # LSTM层数
dropout: 0.1           # Dropout概率
bidirectional: false   # 是否双向
```

#### Mamba配置 (`conf/model_configs/mamba.yaml`)
```yaml
d_model: 128          # 模型维度
d_state: 16           # 状态空间维度
d_conv: 4             # 卷积核大小
expand_factor: 2      # MLP扩展因子
```

#### Transformer配置 (`conf/model_configs/transformer.yaml`)
```yaml
d_model: 128          # 模型维度
n_heads: 8            # 注意力头数
n_layers: 6           # Transformer层数
d_ff: 512             # 前馈网络维度
```

## 实验流程

### 基础实验流程

1. **数据预处理阶段**
   - 数据加载和标准化
   - 序列构建
   - 训练/验证/测试集划分

2. **自编码器训练**
   - 空间特征提取
   - 降维处理
   - 模型保存

3. **预测模型训练**
   - 在潜在空间进行时序建模
   - 选择的模型类型（LSTM/Mamba/Transformer）
   - 超参数优化

4. **端到端微调**（可选）
   - 联合优化自编码器和预测模型
   - 提升整体性能

5. **模型评估**
   - 多种评估指标
   - 可视化结果
   - 性能分析

### 典型实验命令

```bash
# 完整实验流程
python main_pipeline.py \
  experiment.name="lstm_baseline" \
  model.name=lstm \
  train.epochs=100 \
  data.dataset.sequence_length=10

# 快速测试实验
python main_pipeline.py \
  experiment.name="quick_test" \
  data.dataset.use_mini_dataset=true \
  train.epochs=10

# 高质量实验
python main_pipeline.py \
  experiment.name="high_quality" \
  train.epochs=200 \
  train.batch_size=16 \
  model.autoencoder.latent_dim=64
```

## 高级实验

### 1. 模型对比实验

```bash
# 运行多个模型进行对比
python main_pipeline.py --multirun \
  model.name=lstm,mamba,transformer \
  experiment.name="model_comparison"
```

### 2. 超参数搜索

```bash
# LSTM超参数搜索
python main_pipeline.py --multirun \
  model.name=lstm \
  model_configs.hidden_size=64,128,256 \
  model_configs.num_layers=1,2,3 \
  train.optimizer.lr=0.001,0.0005,0.0001

# Mamba超参数搜索
python main_pipeline.py --multirun \
  model.name=mamba \
  model_configs.d_model=64,128,256 \
  model_configs.d_state=8,16,32

# Transformer超参数搜索
python main_pipeline.py --multirun \
  model.name=transformer \
  model_configs.n_heads=4,8,12 \
  model_configs.n_layers=4,6,8
```

### 3. 序列长度影响

```bash
# 不同序列长度实验
python main_pipeline.py --multirun \
  data.dataset.sequence_length=5,10,15,20 \
  experiment.name="sequence_length_study"
```

### 4. 潜在维度影响

```bash
# 不同潜在空间维度
python main_pipeline.py --multirun \
  model.autoencoder.latent_dim=16,32,64,128 \
  experiment.name="latent_dim_study"
```

### 5. 训练策略对比

```bash
# 对比端到端训练和分阶段训练
python main_pipeline.py \
  model.ae_predictive.train_ae_end_to_end=false \
  experiment.name="staged_training"

python main_pipeline.py \
  model.ae_predictive.train_ae_end_to_end=true \
  experiment.name="end_to_end_training"
```

### 6. 高级训练选项

```bash
# 混合精度训练（节省显存）
python main_pipeline.py \
  train.use_mixed_precision=true \
  experiment.name="mixed_precision"

# 梯度累积（模拟大批次）
python main_pipeline.py \
  train.gradient_accumulation_steps=4 \
  train.batch_size=8 \
  experiment.name="gradient_accumulation"
```

## 结果分析

### 1. 查看实验结果

```bash
# 查看最新实验结果
ls -la outputs/$(date +%Y-%m-%d)/

# 查看TensorBoard日志
tensorboard --logdir outputs/tensorboard/
```

### 2. 评估指标解读

- **RMSE**: 均方根误差，越小越好
- **MAE**: 平均绝对误差，越小越好
- **R²**: 决定系数，越接近1越好
- **相对误差**: 相对预测误差百分比

### 3. 可视化分析

实验会自动生成以下可视化：
- 训练损失曲线
- 预测结果对比图
- 误差分布图
- 空间误差分布（如果适用）

### 4. 模型性能对比

```python
# 可以使用以下脚本对比不同模型
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 从日志文件中提取结果进行对比
# （具体实现取决于日志格式）
```

## 常见问题

### Q1: 显存不足怎么办？

**解决方案**：
```bash
# 减小批次大小
python main_pipeline.py train.batch_size=8

# 使用梯度累积
python main_pipeline.py train.gradient_accumulation_steps=4 train.batch_size=4

# 使用混合精度
python main_pipeline.py train.use_mixed_precision=true

# 使用小数据集测试
python main_pipeline.py data.dataset.use_mini_dataset=true
```

### Q2: 训练速度太慢？

**解决方案**：
```bash
# 使用更少的epoch进行快速测试
python main_pipeline.py train.epochs=20

# 增加数据加载线程
python main_pipeline.py data.loader.num_workers=4

# 使用混合精度加速
python main_pipeline.py train.use_mixed_precision=true
```

### Q3: 模型不收敛？

**解决方案**：
```bash
# 调整学习率
python main_pipeline.py train.optimizer.lr=0.0001

# 增加训练epoch
python main_pipeline.py train.epochs=200

# 调整模型复杂度
python main_pipeline.py model_configs.hidden_size=64

# 检查数据质量
python main_pipeline.py data.dataset.use_mini_dataset=true
```

### Q4: 如何选择最佳模型？

**建议流程**：
1. 首先用LSTM作为基线
2. 尝试Mamba（如果数据序列较长）
3. 如果需要更强表征能力，尝试Transformer
4. 进行超参数搜索
5. 使用交叉验证确认结果

### Q5: 如何解释实验结果？

**分析维度**：
1. **数值指标**：RMSE、MAE、R²
2. **可视化分析**：预测图、误差分布
3. **计算效率**：训练时间、内存使用
4. **泛化能力**：测试集表现
5. **稳定性**：多次运行的一致性

## 实验记录建议

### 1. 实验日志记录

```bash
# 为每个实验设置描述性名称
python main_pipeline.py \
  experiment.name="lstm_baseline_$(date +%Y%m%d_%H%M)" \
  # 其他参数...
```

### 2. 重要实验备份

```bash
# 备份重要实验结果
cp -r outputs/2025-05-31/important_experiment/ backup/
```

### 3. 实验对比表格

建议维护一个实验记录表格：

| 实验名称 | 模型类型 | 主要参数 | RMSE | MAE | R² | 训练时间 | 备注 |
|---------|---------|---------|------|-----|----|---------|----- |
| baseline_lstm | LSTM | hidden=128, layers=2 | 0.15 | 0.12 | 0.85 | 2h | 基线模型 |
| mamba_large | Mamba | d_model=256, d_state=32 | 0.13 | 0.10 | 0.88 | 1.5h | 最佳性能 |

## 进阶实验想法

### 1. 集成学习
- 训练多个不同架构的模型
- 使用加权平均或投票机制

### 2. 迁移学习
- 在一个区域训练，在另一个区域测试
- 研究模型的泛化能力

### 3. 注意力机制分析
- 可视化Transformer的注意力权重
- 分析模型关注的时间步

### 4. 消融研究
- 逐步移除输入特征，观察性能变化
- 分析各个组件的贡献

这份实验指南应该能帮助您系统地进行AE-LSTM盐度预测实验。建议从简单的基线实验开始，逐步探索更复杂的配置和高级功能。
